// This module is included in the following assembly:
//
// * backup_and_restore/application_backup_and_restore/oadp-performance/oadp-1-4-performance.adoc
:_mod-docs-content-type: REFERENCE

[id="oadp-1-4-1-performance_{context}"]
= {oadp-short} 1.4.1 scale and performance

The objective of this testing was to run regression tests for backup and restore of {oadp-first} using CSI, File System Backup (FSB) using Kopia, native DataMover, and incremental backup using DataMover.

Also tested was FSB with Kopia using the new feature of setting the Kopia algorithm in the Data Protection Application (DPA). (hashing, encryption, and splitter). An alternative hashing algorithm could provide an improvement of up to 10%

Other test cases show the same results as {oadp-short} 1.4.0.

[NOTE]
====
All testing was conducted on bare metal OpenShift clusters operating within the RDU2 scale laboratory, with isolated hardware, networking, and storage.
====

.Changing the Kopia Algorithm: up to 10% improvement

The implementation of a new hashing value, BLAKE3-256-128, in place of the default Kopia algorithm configuration results in an enhancement of backup results of up to 10%.

.33k secret (ACM) matches improved results from {oadp-short} 1.4.0   

Restore a namespace with 33K secrets. The restore ran, both with and without the `--existing-resource-policy update` flag. The results show a major improvement in both cases compared to {oadp-short} 1.3.0 and the same results as {oadp-short} 1.4.0

.Filesystem restore using Kopia of a single namespace with 100 files, each sized 10 GB

Filesystem restore using Kopia of a single namespace with 100 files, each sized 10 GB. This flow requires requests and limits for the `ephemeral-storage` configuration (DPA), see link:https://issues.redhat.com/browse/OADP-4855[OADP-4855], is found, and as a workaround, NodeAgent pods are restarted to clean the cache.

[NOTE]
====
The issue of Kopia leaving the cache on the worker node is scheduled to be resolved in {oadp-short} 1.5.0.
====

.DataMover

DataMover backup shows the same results as {oadp-short} 1.3.0 and 1.3.1. DataMover restore shows the same results as {oadp-short} 1.3.0 and similar slowness regarding {oadp-short} 1.3.1:

.DataMover Incremental backup

DataMover Incremental Backup shows similar results as (oadp-short) 1.3.0 and 1.3.1:

.DataMover Incremental backup
[width="100%",cols="9%,25%,34%,32%",options="header",]
|===
|Test |OADP 1.3.0 |OADP 1.3.1 |OADP 1.4.1
|backup-vbd-datagen-single-ns-100pods-2gb-cephrbd |00:09:20 |00:09:07 |00:08:51

|restore-vbd-datagen-single-ns-100pods-2gb-cephrbd |00:24:27 |00:34:11 |00:13:23

|backup-vbd-datagen-single-ns-1pod-500gb-cephrbd |00:09:27 |00:09:11 |00:08:32

|restore-vbd-datagen-single-ns-1pod-500gb-cephrbd |00:26:14 |00:17:35 |00:26:10
|===

.Duration of the CephFS restore compared to the CephRBD restore

Restoring a large Container Storage Interface (CSI) snapshot on Ceph RBD is substantially faster when compared to CephFS:

.Duration of the CephFS restore compared to the CephRBD restore
[width="100%",cols="9%,25%,34%,32%",options="header",]
|===
|Test |OADP 1.3.0 |OADP 1.3.1 |OADP 1.4.1
|backup-vbd-datagen-single-ns-100pods-2gb-cephrbd |00:09:20 |00:09:07 |00:08:51

|restore-vbd-datagen-single-ns-100pods-2gb-cephrbd |00:24:27 |00:34:11 |00:13:23

|backup-vbd-datagen-single-ns-1pod-500gb-cephrbd |00:09:27 |00:09:11 |00:08:32

|restore-vbd-datagen-single-ns-1pod-500gb-cephrbd |00:26:14 |00:17:35 |00:26:10
|===

.PVC compared to PV create time

The following commands show the gap between PersistentVolumeClaim (PVC) create time and  PersistentVolume (PV) create time.

Once the PV is created and the restore-CR is in `finalizing` status, the restore-CR status is changed to `Completed`.

. Verify that the persistent volume claim is bound:
+
[source,terminal]
----
$ oc get pvc -ndatagen-1pod-3000g-fs
----

+
Example output:

+
[source,terminal]
----
pvc-busy-data-fs-1pod-3000g-1   Bound
pvc-25682db5-1da6-46f9-8e48-13332eaca35e   4000Gi     RWO
ocs-storagecluster-cephfs   <unset>                 45h
----

. Verify that the persistent volume is bound:
+
[source,terminal]
----
$ oc get pv | grep datagen-1pod-3000g-fs
----

+
Example output:

+
[source,terminal]
----
pvc-25682db5-1da6-46f9-8e48-13332eaca35e   4000Gi     RWO            Delete
Bound    datagen-1pod-3000g-fs/pvc-busy-data-fs-1pod-3000g-1
ocs-storagecluster-cephfs     <unset>              29h
----
