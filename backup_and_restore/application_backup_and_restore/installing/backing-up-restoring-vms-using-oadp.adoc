:_mod-docs-content-type: ASSEMBLY
include::_attributes/common-attributes.adoc[]
include::_attributes/attributes-openshift-dedicated.adoc[]
[id="backing-up-restoring-vms-using-oadp"]
= Backing up and restoring up virtual machines using OADP examples
:context: oadp-backing-up-vms
:installing-oadp-kubevirt:

toc::[]

// add a couple of examples from the test cases
[id="backing-up-restoring-fedora-vm-block-pv"]
== Backup and restore a Fedora Virtual Machine with native data mover

The following is an example of backing up and restoring a Fedora virtual machine (VM) deployed with large file over block Persistent Volume (PV) using {oadp-first}.

.Prerequisites

. {oadp-short} operator installed on {OCP} (OCP) cluster. For more information, see xref:../../../backup_and_restore/application_backup_and_restore/installing/about-installing-oadp.adoc#about-installing-oadp[{oadp-short} Operator].
. An available object storage for the backup location
. A file consisting of cloud credentials
. {VirtProductName} Operator installed
. Container Storage Interface (CSI) Storage Provisioner supporting Block volumes


.Procedure

. Create a DPA instance with CSI and Node Agent enabled:

+
[source,terminal]
----
cat <<EOF | oc create -f -
apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  namespace: openshift-adp
  name: ts-dpa
spec:
  configuration:
    nodeAgent:
      enable: true
      uploaderType: kopia
    velero:
      defaultPlugins:
      - openshift
      - aws
      - csi
  backupLocations:
    - name: default
      velero:
        provider: aws
        default: true
        objectStorage:
          bucket: $BUCKET
          prefix: velero
          region: $REGION
        config:
          profile: default
          region: $REGION
EOF
----

. Create a secret:
+
[source,terminal]
----
$ oc create secret generic <secret-name> -n openshift-adp --from-file cloud=<credentials file path>
----

+
[NOTE]
====
The Data Protection Application (DPA) configuration can be different for each bucket.
====

. Verify that the DataProtectionApplication (DPA) is reconciled.

. Verify the Velero and Node agents pods are created and running:
+
[source,terminal]
----
$ oc get pod -n openshift-adp
----
+
Output
+
[source,terminal]
----
NAME                                                              READY   STATUS              RESTARTS   AGE
node-agent-p4j6c                                                  1/1     Running             0          13m
openshift-adp-controller-manager-54877df7c4-sw6zj                 1/1     Running             0          162m
velero-5d6cbbc5d-gqpls                                            1/1     Running             0          13m
----

. Verify the node agent is running in `privilege` mode, outputting in YAML:

+
[source,terminal]
----
$ oc get po/node-agent-p4j6c  -o yaml
----
+
.Example output
+
[source,terminal]
----
  containers:
  - args:
    - node-agent
    - server
    command:
    - /velero
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: spec.nodeName
    - name: VELERO_NAMESPACE
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.namespace
    - name: VELERO_SCRATCH_DIR
      value: /scratch
    image: registry.redhat.io/oadp/oadp-velero-rhel9@sha256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    imagePullPolicy: Always
    name: node-agent
    resources:
      requests:
        cpu: 100m
        memory: 64Mi
    securityContext:
      privileged: true <1>
----
+
<1> Node agent is running in `privilege` mode.

. Perform a backup:
+
[source,terminal]
----
$ oc create -f backup.yml
apiVersion: velero.io/v1
kind: Backup
metadata:
  name: test-backup
  labels:
    velero.io/storage-location: default
  namespace: openshift-adp
spec:
  hooks: {}
  includedNamespaces:
  - test-vm
  snapshotMoveData: true
  storageLocation: ts-dpa-1
  ttl: 720h0m0s
----

. Verify the clone PVC volumeMode:
+
[source,terminal]
----
$ oc get pvc/ocp-kubevirt-df735757-6c10-11ee-9572-0c9a3c9340c2-z5hv  -o jsonpath='{.spec.volumeMode}'
----
+
.Example output
+
[source,terminal]
----
Block
----
. Wait until the backups is completed successfully:
+
[source,terminal]
----
$ oc get backup test-backup -n openshift-adp -o jsonpath='{.status.phase}'
----
+
.Example output
+
[source,terminal]
----
Completed
----

. Verify the dataupload CR's status is completed
+
[source,terminal]
----
$ oc get dataupload
----
+
.Example output
+
[source,terminal]
----
NAME                 STATUS      STARTED   BYTES DONE   TOTAL BYTES   STORAGE LOCATION   AGE    NODE
test-backup4         Completed   105s      50223065     50223065      ts-dpa-1           105s   oadp-51230-56rtw-worker
----

. Verify that there are no VolumeSnapshots resources remaining in the {oadp-short} namespace:
+
[source,terminal]
----
$ oc get vs -n openshift-adp
----
+
.Example output
+
[source,terminal]
----
No resources found in openshift-adp namespace.
----

. Verify that there are no persistent volume claims (PVCs) remaining in the {oadp-short} namespace `openshift-adp`:
+
[source,terminal]
----
$ oc get pvc -n openshift-adp
----
+
.Example output
+
[source,terminal]
----
No resources found in openshift-adp namespace.
----

. Delete the application namespace:
+
[source,terminal]
----
$ appm remove ocp-kubevirt
----

. Check that the application has been deleted:
+
[source,terminal]
----
$ oc get project ocp-kubevirt
----
+
.Example output
+
[source,terminal]
----
Error from server (NotFound): namespaces "ocp-kubevirt" not found
----

. Perform a restore:
+
[source,terminal]
----
$ oc create -f restore.yml
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: test-restore1
  namespace: openshift-adp
spec:
  backupName: test-backup
  excludedResources:
  - nodes
  - events
  - events.events.k8s.io
  - backups.velero.io
  - restores.velero.io
  - resticrepositories.velero.io
  restorePVs: true
----

. Verify the clone PVC volumeMode is present in the namespace `openshift-adp ns`:
+
[source,terminal]
----
$ oc get pvc/  -o jsonpath='{.spec.volumeMode}'ocp-kubevirt-df735757-6c10-11ee-9572-0c9a3c9340c2-z5hvf
----
+
.Example output
+
[source,terminal]
----
Block
----

. Wait until the restore finishes successfully:
+
[source,terminal]
----
$ oc get restore test-restore1 -n openshift-adp -o jsonpath='{.status.phase}'
----
+
.Example output
+
[source,terminal]
----
Completed
----

. Verify the datadownload CR is completed successfully:
+
[source,terminal]
----
$ oc get datadownload
----
+
.Example output
+
[source,terminal]
----
NAME                  STATUS      STARTED   BYTES DONE   TOTAL BYTES   STORAGE LOCATION   AGE   NODE
test-restore3-nv4n2   Completed   55s       50223065     50223065      ts-dpa-1           55s   oadp-51230-56rtw-worker
----

. Verify that there are no PVCs left on the namespace  `openshift-adp ns`:
+
[source,terminal]
----
$ oc get pvc
----
.Example output
+
[source,terminal]
----
No resources were found in openshift-adp namespace.
----

. Verify the VM is running:
+
[source,terminal]
----
$ appm validate ocp-kubevirt && echo ok!
----
+
.Example output
+
[source,terminal]
----
...
2024-02-14 18:22:02,711.711 - INFO: TASK [ocp-kubevirt : Wait for VM to be Running & Ready]
2024-02-14 18:22:02,711.711 - INFO: ok: [localhost]
2024-02-14 18:22:03,924.924 - INFO:
2024-02-14 18:22:03,925.925 - INFO: TASK [ocp-kubevirt : Wait for VM to have AgentConnected status True indicating the guest agent is running] ***
2024-02-14 18:22:03,925.925 - INFO: ok: [localhost]
2024-02-14 18:22:03,951.951 - INFO:
2024-02-14 18:22:03,951.951 - INFO: PLAY RECAP
2024-02-14 18:22:03,951.951 - INFO: localhost                  : ok=5    changed=1    unreachable=0    failed=0    skipped=4    rescued=0    ignored=0
2024-02-14 18:22:04,115.115 - DEBUG: Removed private data directory: /tmp/tmpic2dgato
ok! <1>
----
+
<1> `ok!` is echoed, showing the VM is running.

. Verify the PVC holding the VM is provided with `Block` mode PV:
+
[source,terminal]
----
$ oc get pvc/test-vm-dv -o jsonpath='{.spec.volumeMode}'
----
+
.Example output
+
[source,terminal]
----
Block
----

. Verify the PVC is mounted properly to the `virt-launcher` pod
+
[source,terminal]
----
$ oc get pvc/test-vm-dv -o jsonpath='{.status.phase}'
----
+
.Example output
+
[source,terminal]
----
Bound
----

. Verify VM file content Secure Hash Algorithms (SHA) digest:
+
[source,terminal]
----
$ sha256sum /tmp/random_data-from-v.bin
----
+
.Example output
+
[source,terminal]
----
XXXXXXXXXXXXXXXXXXX6c8d3b2488af14e116292a21dd15fbedb724014673  /tmp/random_data-from-vm-after-restore.bin
----


[id="backing-up-restoring-windows-vm-block-pv"]
== Backup and restore a Windows Virtual Machine with native data mover

The following is an example of backing up and restoring a Windows virtual machine (VM) deployed with large file over block Persistent Volume (PV) using {oadp-first}.

.Prerequisites

. {oadp-short} operator installed on OCP cluster. For more information, see xref:../../../backup_and_restore/application_backup_and_restore/installing/about-installing-oadp.adoc#about-installing-oadp[{oadp-short} Operator]
. An available object storage for the backup location.
. A file consisting of cloud credentials keys. For more information, see xref:../../../backup_and_restore/application_backup_and_restore/installing/about-installing-oadp.adoc#about-installing-oadp[{oadp-short} Operator]
. {VirtProductName} Operator installed
. Container Storage Interface (CSI) Storage Provisioner supporting block volumes


.Procedure

. Create a DPA instance with CSI and Node Agent enabled:

+
[source,terminal]
----
cat <<EOF | oc create -f -
apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  namespace: openshift-adp
  name: ts-dpa
spec:
  configuration:
    nodeAgent:
      enable: true
      uploaderType: kopia
    velero:
      defaultPlugins:
      - openshift
      - aws
      - csi
  backupLocations:
    - name: default
      velero:
        provider: aws
        default: true
        objectStorage:
          bucket: $BUCKET
          prefix: velero
          region: $REGION
        config:
          profile: default
          region: $REGION
EOF
----

. Create a secret:
+
[source,terminal]
----
$ oc create secret generic <secret-name> -n openshift-adp --from-file cloud=<credentials file path>
----

. Verify DPA is `reconciled` successfully and there are no errors.

. Verify the Velero and Node agents pods are created and running.
+
[source,terminal]
----
$ oc get pod -n openshift-adp
----

+
.Example output
+
[source,terminal]
----
NAME                                                              READY   STATUS              RESTARTS   AGE
node-agent-p4j6c                                                  1/1     Running             0          13m
node-agent-pd546                                                  1/1     Running             0          13m
node-agent-wn4xr                                                  1/1     Running             0          13m
openshift-adp-controller-manager-54877df7c4-sw6zj                 1/1     Running             0          162m
velero-5d6cbbc5d-gqpls                                            1/1     Running             0          13m
----

. Verify the node agents are running in `privilege` mode:
+
[source,terminal]
----
$ oc get po/node-agent-p4j6c  -o yaml
----
+
.Example output
+
[source,terminal]
----
  containers:
  - args:
    - node-agent
    - server
    command:
    - /velero
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: spec.nodeName
    - name: VELERO_NAMESPACE
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.namespace
    - name: VELERO_SCRATCH_DIR
      value: /scratch
    image: registry.redhat.io/oadp/oadp-velero-rhel9@sha256:a703c7c9bd75a8072004bf9c968b8aefbfb35fa7121b46700875a7b4c3f208fc
    imagePullPolicy: Always
    name: node-agent
    resources:
      requests:
        cpu: 100m
        memory: 64Mi
    securityContext:
      privileged: true
----



. Deploy a Virtual Machine with a data volume template, for example:
+
[source,terminal]
----
apiVersion: kubevirt.io/v1
kind: VirtualMachine
metadata:
  annotations:
    kubemacpool.io/transaction-timestamp: '2024-02-02T11:25:23.989536538Z'
    vm.kubevirt.io/validations: |
      [
        {
          "name": "minimal-required-memory",
          "path": "jsonpath::.spec.domain.memory.guest",
          "rule": "integer",
          "message": "This VM requires more memory.",
          "min": 2147483648
        }, {
          "name": "windows-virtio-bus",
          "path": "jsonpath::.spec.domain.devices.disks[*].disk.bus",
          "valid": "jsonpath::.spec.domain.devices.disks[*].disk.bus",
          "rule": "enum",
          "message": "virtio disk bus type has better performance, install virtio drivers in VM and change bus type",
          "values": ["virtio"],
          "justWarning": true
        }, {
          "name": "windows-disk-bus",
          "path": "jsonpath::.spec.domain.devices.disks[*].disk.bus",
          "valid": "jsonpath::.spec.domain.devices.disks[*].disk.bus",
          "rule": "enum",
          "message": "disk bus has to be either virtio or sata or scsi",
          "values": ["virtio", "sata", "scsi"]
        }, {
          "name": "windows-cd-bus",
          "path": "jsonpath::.spec.domain.devices.disks[*].cdrom.bus",
          "valid": "jsonpath::.spec.domain.devices.disks[*].cdrom.bus",
          "rule": "enum",
          "message": "cd bus has to be sata",
          "values": ["sata"]
        }
      ]
  labels:
    app: win10-orange-barnacle-28
    vm.kubevirt.io/template: windows10-desktop-medium
    vm.kubevirt.io/template.namespace: openshift
    vm.kubevirt.io/template.revision: '1'
    vm.kubevirt.io/template.version: v0.27.0
  name: win10-orange-barnacle-28
  namespace: test-vm
  uid: 73699269-5b1d-4127-a7af-41f6320b3669
spec:
  dataVolumeTemplates:
    - apiVersion: cdi.kubevirt.io/v1beta1
      kind: DataVolume
      metadata:
        creationTimestamp: null
        name: win10-orange-barnacle-28
      spec:
        pvc:
          volumeMode: Block
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 120Gi
          storageClassName: ocs-storagecluster-ceph-rbd-virtualization
        source:
          http:
            url: 'http://cnv-qe-server.rhos-psi.cnv-qe.rhood.us/files/cnv-tests/windows-images/win_10.qcow2'
  running: false
  template:
    metadata:
      annotations:
        vm.kubevirt.io/flavor: medium
        vm.kubevirt.io/os: windows10
        vm.kubevirt.io/workload: desktop
      creationTimestamp: null
      labels:
        kubevirt.io/domain: win10-orange-barnacle-28
        kubevirt.io/size: medium
    spec:
      architecture: amd64
      domain:
        clock:
          timer:
            hpet:
              present: false
            hyperv: {}
            pit:
              tickPolicy: delay
            rtc:
              tickPolicy: catchup
          utc: {}
        cpu:
          cores: 1
          sockets: 1
          threads: 1
        devices:
          disks:
            - disk:
                bus: sata
              name: rootdisk
            - cdrom:
                bus: sata
              name: windows-drivers-disk
          inputs:
            - bus: usb
              name: tablet
              type: tablet
          interfaces:
            - macAddress: '02:04:b9:00:00:08'
              masquerade: {}
              model: e1000e
              name: default
        features:
          acpi: {}
          apic: {}
          hyperv:
            frequencies: {}
            ipi: {}
            reenlightenment: {}
            relaxed: {}
            reset: {}
            runtime: {}
            spinlocks:
              spinlocks: 8191
            synic: {}
            synictimer:
              direct: {}
            tlbflush: {}
            vapic: {}
            vpindex: {}
        machine:
          type: pc-q35-rhel9.2.0
        memory:
          guest: 4Gi
        resources: {}
      networks:
        - name: default
          pod: {}
      terminationGracePeriodSeconds: 3600
      volumes:
        - dataVolume:
            name: win10-orange-barnacle-28
          name: rootdisk
        - containerDisk:
            image: 'oE55y-ApqAP-WMw2Z-FjwEZ'
          name: windows-drivers-disk
----

. Verify the status of the VM.

. Verify the PVC holding the VM is provided with Block mode PV;
+
[source,terminal]
----
 $ oc get pvc/test-vm-dv -o jsonpath='{.spec.volumeMode}'
----

. .Example output
+
[source,terminal]
----
Block
----

. Verify the PVC holding the VM is mounted Properly to the virt-launcher pod;
+
[source,terminal]
----
$ oc get pvc/test-vm-dv -o jsonpath='{.status.phase}'
----

. .Example output
+
[source,terminal]
----
Bound
----

. Create a file with timestamp and copy the file to the vm, making a note of the value:
+
[source,terminal]
----
$ dd if=/dev/urandom of=/tmp/random_data.bin bs=1M count=1000
----

. .Example output
+
[source,terminal]
----
1000+0 records in
1000+0 records out
1048576000 bytes (1.0 GB, 1000 MiB) copied, 2.773 s, 378 MB/s
----

. Write the Secure Hash Algorithms (SHA) to `/tmp/random_data.bin`
+
[source,terminal]
----
$ sha256sum /tmp/random_data.bin
----

. .Example output
+
[source,terminal]
----
9999b9ba878615968a49976c8d3b2488af14e116292a21dd15fbedb724014673  /tmp/random_data.bin
----

.
+
[source,terminal]
----
$ virtctl -nocp-kubevirt scp /tmp/random_data.bin administrator@test-vm:\c:\random_data.bin
----

. .Example output
+
[source,terminal]
----
fedora@test-vm.ocp-kubevirt's password:  administrator
random_data.bin                                                                                                                                                100% 1000MB   4.2MB/s   03:56
----

. Verify the VM file content with the Secure Hash Algorithms (SHA) digest:
+
[source,terminal]
----
$ virtctl -nocp-kubevirt scp administrator@test-vm:\c:\random_data.bin /tmp/random_data-from-vm-after-restore.bin
----

. .Example output
+
[source,terminal]
----
administrator@test-vm.ocp-kubevirt's password: <password>

random_data.bin   100%   64MB 838.1KB/s  03:56
----

.. Issue
+
[source,terminal]
----
$ sha256sum /tmp/random_data-from-v.bin
----

. .Example output
+
[source,terminal]
----
9999b9ba878615968a49976c8d3b2488af14e116292a21dd15fbedb724014673  /tmp/random_data-from-vm-after-restore.bin
----


